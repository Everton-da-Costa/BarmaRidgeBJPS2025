---
title: "Application: Modeling Relative Humidity in Brasília"
subtitle: "Reproducing the Empirical Application from Cribari-Neto, Costa, & Fonseca (2025)"
author: "Everton da Costa"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
    fig_caption: true
vignette: >
  %\VignetteIndexEntry{Application: Relative Humidity in Brasília}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 3.5,
  fig.align = "center",
  warning = FALSE,
  message = FALSE
)

library(BarmaRidgeBJPS2025)
library(forecast)   # time series
library(ggplot2)    # plotting
library(zoo)        # yearmon handling
library(dplyr)      # data manipulation
library(gridExtra)  # grid.arrange for plots

# Bootstrap libraries
library(doMC)
library(doRNG)
```

# Application: Relative Humidity in Brasília

## Introduction

In this vignette, we reproduce an empirical application from Cribari-Neto, Costa, & Fonseca (2025) using the `BarmaRidgeBJPS2025` package. We show how numerical instability can arise when modeling an empirical time series and how the package's functions provide stable and reliable solutions.

The analysis focuses on fitting a $\beta\text{ARMA(1,4)}$ model to a subsample of monthly relative humidity data from Brasília, Brazil, where standard estimation methods are known to produce implausible results. This example corresponds to **Table 12** in the paper.

**Key Reference:** 
Cribari-Neto, F., Costa, E., & Fonseca, R. V. (2025). 
Numerical stability enhancements in beta autoregressive moving average model estimation.

```{r, config_data_visualization, include=FALSE}
# Series size and end time
sample_size <- length(brasilia_ts)
end_time_series <- time(brasilia_ts)[sample_size] + 1

# Size font of the plot
ggplot_size_font <- 9

# ggplot theme
ggplot_theme <- theme(
  legend.position = "bottom",
  title = element_text(size = ggplot_size_font),
  axis.text = element_text(size = ggplot_size_font),
  axis.title = element_text(size = ggplot_size_font),
  legend.text = element_text(size = ggplot_size_font),
  legend.title = element_text(size = ggplot_size_font)
  )

# ggplot theme forecast plot
ggplot_theme_forecast <- theme(
  legend.position = "right",
  title = element_text(size = ggplot_size_font),
  axis.text = element_text(size = ggplot_size_font),
  axis.title = element_text(size = ggplot_size_font),
  legend.text = element_text(size = ggplot_size_font),
  legend.title = element_text(size = ggplot_size_font)
)

# y-axis scale
ggplot_scale_y <-
  scale_y_continuous(
    breaks = seq(0.0, 1.00, 0.10)
    # limits = c(0.1, 1.0)
  )

# x-axis scale
ggplot_scale_x <- scale_x_continuous(
  breaks = seq(1999, end_time_series, 2),
  limits = c(1999, end_time_series)
)
```

## Data and Exploratory Analysis

The dataset consists of 306 monthly observations of the average relative humidity in Brasília, Brazil, from January 1999 to June 2024. The data is sourced from NASA's POWER project. Relative humidity is a proportion, naturally bounded between 0 and 1, making it a perfect candidate for beta regression-based models.

The time series exhibits clear seasonal fluctuations, confirmed by the sinusoidal decay in the autocorrelation function. Descriptive statistics reveal a left-skewed distribution with significant variation (standard deviation of 0.16). To account for seasonality, we use harmonic regressors $(s_t =sin(2\pi t/12)$ and $c_t  =cos(2\pi t/12))$ in the modeling process.

```{r, ggplot_brasilia, include=FALSE}
# -------------------------------------------------------------------------- #
# Time series plot
# -------------------------------------------------------------------------- #
ggplot_brasilia <- ggplot(brasilia_df, aes(time, y)) +
  geom_point(size = 0.5) +
  geom_line(aes(group = 1)) +
  ggplot_scale_x +
  ggplot_scale_y +
  ggplot_theme +
  guides(colour = guide_legend(title = "Temporary regimes"))

# -------------------------------------------------------------------------- #
# Autocorrelation function (ACF) plot
# -------------------------------------------------------------------------- #
ggacf_plot <- ggAcf(brasilia_ts) +
  ggtitle(" ") +
  xlab("Lag") +
  ylab("ACF")

# -------------------------------------------------------------------------- #
# Partial autocorrelation function (PACF) plot
# -------------------------------------------------------------------------- #
ggpacf_plot <- ggPacf(brasilia_ts) +
  ggtitle(" ") +
  xlab("Lag") +
  ylab("PACF")
```

```{r, print_ggplot_brasilia, message=FALSE, echo=FALSE, fig.height=5, fig.cap="Relative humidity in Brasília (top), with its corresponding autocorrelation function (bottom left) and partial autocorrelation function (bottom right)."}
# -------------------------------------------------------------------------- #
# Grid all plots
# -------------------------------------------------------------------------- #
grid.arrange(
  ggplot_brasilia,
  ggacf_plot,
  ggpacf_plot,
  layout_matrix = rbind(c(1, 1), c(2, 3))
)
```

```{r, descriptive, include=FALSE}
# -------------------------------------------------------------------------- #
# Descriptive statistics: Useful volume of the brasilia
# -------------------------------------------------------------------------- #
descriptive_df <- data.frame(
  min             = min(brasilia_ts),
  max             = max(brasilia_ts),
  median          = median(brasilia_ts),
  mean            = mean(brasilia_ts),
  sd              = sd(brasilia_ts),
  skewness        = moments::skewness(brasilia_ts),
  excess_kurtosis = moments::kurtosis(brasilia_ts)
)

# Round to two decimals
descriptive_df <- round(descriptive_df, 2)
```

```{r, print_descriptive, echo=FALSE}
knitr::kable(
  descriptive_df,
  caption = 
    "Descriptive statistics of the brasilia relative humidity in Brasília."
)
```

## A Case of Instability: The Sub-sample Analysis

To highlight the estimation challenges, we focus on a specific 150-observation subsample from April 2006 to September 2018, was identified in the original research as being particularly problematic for the standard estimation.

The plot below shows the full time series, with the problematic subsample highlighted between the dashed red lines. This visualization helps contextualize the portion of the data that causes estimation issues.

```{r, sample, include=FALSE}

sample_size <- 150 # The length of the training sample
n_test <- 6        # The number of observations for the final test set

# The lag in months (how far back to go) 
# In this example specifies the data from April 2006 to September 2018.
lag_months <- 69   

# Define n_obs before using it.
n_obs <- length(brasilia_ts)

# Train-test split index
split_idx <- n_obs - n_test

# The end of the primary training period (our anchor point)
end_train <- time(brasilia_ts)[split_idx]

# The end of our lagged sample window
end_train_lag <- end_train - (lag_months / 12)

# The start of our lagged sample window
start_train_lag <- end_train_lag - deltat(brasilia_ts) * (sample_size - 1)

# Sample
# ----------------------------------------------------------------------- #
y_sample_ts <- window(brasilia_ts,
                      start = start_train_lag,
                      end = end_train_lag)
```

```{r, ggplot_brasilia_subsample, include=FALSE}
len_y_sample <- length(y_sample_ts)

start_subsample_time <- time(y_sample_ts)[1]
end_subsample_time <- time(y_sample_ts)[len_y_sample]

# -------------------------------------------------------------------------- #
# Time series plot
# -------------------------------------------------------------------------- #
ggplot_brasilia <- ggplot(brasilia_df, aes(time, y)) +
  geom_point(size = 0.5) +
  geom_line(aes(group = 1)) +
  ggplot_scale_x +
  ggplot_scale_y +
  ggplot_theme +
  guides(colour = guide_legend(title = "Relative humidity in Brasília")) +

  # Vertical line for the start of the sub-sample
  geom_vline(
    xintercept = start_subsample_time,
    linetype = "dashed",
    size = 0.5,
    color = "red"
  ) +

  # Vertical line for the end of the sub-sample
  geom_vline(
    xintercept = end_subsample_time,
    linetype = "dashed",
    size = 0.5,
    color = "red"
  )

# -------------------------------------------------------------------------- #
# Autocorrelation function (ACF) plot
# -------------------------------------------------------------------------- #
ggacf_plot <- ggAcf(brasilia_ts) +
  ggtitle(" ") +
  xlab("Lag") +
  ylab("ACF")

# -------------------------------------------------------------------------- #
# Partial autocorrelation function (PACF) plot
# -------------------------------------------------------------------------- #
ggpacf_plot <- ggPacf(brasilia_ts) +
  ggtitle(" ") +
  xlab("Lag") +
  ylab("PACF")
```

```{r, print_ggplot_brasilia_subsample, message=FALSE, echo=FALSE, fig.height=5, fig.cap=" Relative humidity in Brasília (top), with its corresponding autocorrelation function (bottom left) and partial autocorrelation function (bottom right)."}
# -------------------------------------------------------------------------- #
# Grid all plots
# -------------------------------------------------------------------------- #
grid.arrange(
  ggplot_brasilia,
  ggacf_plot,
  ggpacf_plot,
  layout_matrix = rbind(c(1, 1), c(2, 3))
)
```


### Feature Engineering

Due to the strong seasonality, we include harmonic regressors to capture the strong seasonal patterns identified in the exploratory data analysis.

* Harmonic Regressors: A pair of sine (`hs`) and cosine (`hc`) waves with a 12-month frequency. These are highly effective for modeling smooth, repeating annual cycles like those seen in humidity data.

```{r, regressor, include=FALSE}
# Get Time Series Frequency
freq <- frequency(y_sample_ts)

# Create Trend Regressors
trend_index <- seq_along(y_sample_ts)
trend_index_hat <- (max(trend_index) + 1):(max(trend_index) + n_test)

# Create Harmonic Regressors 
hs <- sin(2 * pi * trend_index / freq)
hc <- cos(2 * pi * trend_index / freq)
hs_hat <- sin(2 * pi * trend_index_hat / freq)
hc_hat <- cos(2 * pi * trend_index_hat / freq)


# Final
regressors_list <- list(
    trend_index = trend_index,
    trend_index_hat = trend_index_hat,
    hs = hs,
    hc = hc,
    hs_hat = hs_hat,
    hc_hat = hc_hat
)

```

## Model Fitting and Results

Now we fit the $\beta\text{ARMA(1,4)}$ model to the subsample using both the standard conditional maximum likelihood estimator (CMLE) and the penalized estimator (PCMLE). The goal is to compare the parameter estimates and demonstrate the stabilizing effect of the ridge penalty. We also include results from the seasonal block bootstrap as a complementary strategy.

### Standard Method: Conditional Maximum Likelihood (CMLE)

First, we fit the model using the standard CMLE by setting penalty = 0. As the results show, this approach produces implausible parameter estimates for this subsample, highlighting the numerical instability issue.

```{r, estimation_setup}
# Model Specification
ar_vec <- 1
ma_vec <- 1:4
```

```{r, estimates_mle}
# Fit the unpenalized BARMA model (standard CMLE)
fit_default <- barma(
  y = y_sample_ts,
  ar = ar_vec,
  ma = ma_vec,
  penalty = 0,
  h1 = n_test,
  X = cbind(
    hs = regressors_list$hs,
    hc = regressors_list$hc
  ),
  X_hat = cbind(
    hs_hat = regressors_list$hs_hat,
    hc_hat = regressors_list$hc_hat
  )
)

```

### Proposed Solution 1: Penalized CMLE (PCMLE)

Next, we apply the ridge penalization scheme. This method adds a small penalty term to the log-likelihood function, which enhances its curvature and makes the optimization process more stable. The penalty is intentionally small, designed only to provide stability without significantly biasing the results.

```{r, estimates_pmle}
# Ridge Penalty
a_max <- max(ar_vec, ma_vec)
penalty <- 1 / (len_y_sample - a_max)^(0.9)

# Fit the penalized BARMA model (PCMLE)
fit_ridge <- barma(
  y = y_sample_ts,
  ar = ar_vec,
  ma = ma_vec,
  penalty = penalty,
  h1 = n_test,
  X = cbind(
    hs = regressors_list$hs,
    hc = regressors_list$hc
  ),
  X_hat = cbind(
    hs_hat = regressors_list$hs_hat,
    hc_hat = regressors_list$hc_hat
  )
)
```

```{r, print_estimates}
# Data frame with CMLE and PCMLE estimates
estimates <- cbind(
  CMLE = as.numeric(fit_default$coef),
  PCMLE = as.numeric(fit_ridge$coef)
)

estimates_df <- data.frame(estimates)

# Row names of the LaTeX table
ar_names <- paste0("$\\varphi_", ar_vec, "$")
ma_names <- paste0("$\\theta_", ma_vec, "$")
barma_names <- c("$\\alpha$", ar_names, ma_names, "$\\phi$")
regressors_names <- c("$\\beta_1$ (sin)", "$\\beta_2$ (cos)")

rownames(estimates_df) <- c(barma_names, regressors_names)
estimates_df <- round(estimates_df, 4)

knitr::kable(
  estimates_df,
  caption = "Parameter estimates for the $\\beta\\text{ARMA(1,4)}$ model;
  relative humidity in Brasília, data from April 2006 to September 2018."
)

```

### Proposed Solution 2: Seasonal Block Bootstrap

As a complementary strategy, especially for cases with seasonality, we use the seasonal block bootstrap to obtain the estimates.

```{r, bootstrap_conf}
# -------------------------------------------------------------------------- #
# Bootstrap Configuration
# -------------------------------------------------------------------------- #
# Set a seed for the random number generator to ensure reproducibility.
seed <- 14
# Define the number of CPU cores to use for parallel execution.
n_cores <- 2
# Specify the total number of bootstrap replications to be performed.
n_boot_rep <- 200
```

```{r, bootstrap12}
# -------------------------------------------------------------------------- #
# Run Bootstrap Procedures
# -------------------------------------------------------------------------- #

# Perform the seasonal block bootstrap using a block length of 12.
# This value corresponds to the annual seasonal cycle (12 months).
ridge_boot_seasonal_block12 <- BARMAX_ridge_bootstrap_seasonal_parallel(
  n_cores = n_cores,
  y = y_sample_ts,
  seed = seed,
  ar_vec = ar_vec,
  ma_vec = ma_vec,
  fit_ridge = fit_ridge,
  penalty = penalty,
  regressors_list = regressors_list,
  block_length = 12,
  n_boot_rep = n_boot_rep
)
```

```{r, bootstrap24}
# Repeat the bootstrap procedure with a different block length of 24.
# This helps assess the sensitivity of the estimates to the block size.
ridge_boot_seasonal_block24 <- BARMAX_ridge_bootstrap_seasonal_parallel(
  n_cores = n_cores,
  y = y_sample_ts,
  seed = seed,
  ar_vec = ar_vec,
  ma_vec = ma_vec,
  fit_ridge = fit_ridge,
  penalty = penalty,
  regressors_list = regressors_list,
  block_length = 24,
  n_boot_rep = n_boot_rep
)
```

### Comparison of Results

The table below summarizes the estimates from all three methods, corresponding to **Table 12** in the paper.

The table below summarizes the estimates from all methods, corresponding to ***Table 12*** in the paper. The standard estimation method (CMLE) shows clear signs of instability. For instance, the autoregressive parameter $(\varphi_1)$ is $-0.5736$ (CMLE) compared to a more plausible $0.3452$ (PCMLE). Additionally, the first moving average parameter $(\theta_1)$ is dramatically inflated under CMLE $(1.2184)$ compared to the moderate PCMLE estimate $(0.2853)$. In stark contrast, the penalized (PCMLE) and bootstrap estimates are stable and well-behaved, demonstrating the effectiveness of the proposed methods.

```{r, print_bootstrap_estimates}
# -------------------------------------------------------------------------- #
# Format and Print Bootstrap Estimates
# -------------------------------------------------------------------------- #

# Combine original model estimates with the mean bootstrap results.
# The new columns are from the runs with block lengths 12 and 24.
estimates_final_df <- cbind(
  estimates_df,
  PCMLE12 = ridge_boot_seasonal_block12$mean_bootstrap_estimates,
  PCMLE24 = ridge_boot_seasonal_block24$mean_bootstrap_estimates
)

# Rename the new columns using LaTeX for better table formatting in the report.
# PCMLE* is the Penalized Conditional Maximum Likelihood Estimator.
colnames(estimates_final_df)[3] <- "$\\text{PCMLE}^*_{12}$"
colnames(estimates_final_df)[4] <- "$\\text{PCMLE}^*_{24}$"

# Round all numerical estimates to four decimal places for presentation.
estimates_final_df <- round(estimates_final_df, 4)

# Generate a formatted table for the report using the kable() function.
# A caption is added to describe the table's content.
knitr::kable(
  estimates_final_df,
  caption = "Parameter estimates for the $\\beta\\text{ARMA(1,4)}$ model;
  relative humidity in Brasília, data from April 2006 to September 2018."
)
```

## Conclusion

This vignette demonstrated the application of the `BarmaRidgeBJPS2025` package in handling numerical instability. We showed that for the Brasília relative humidity dataset, standard CMLE produced implausible estimates on a specific subsample. In contrast, the Penalized CMLE (PCMLE) approach, along with the seasonal block bootstrap, provided stable and reliable results, underscoring the value of these methods for time series analysis.
